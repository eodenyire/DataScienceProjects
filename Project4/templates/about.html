{% extends "base.html" %}

{% block title %}About - Traffic Sign Classification{% endblock %}

{% block extra_css %}
<style>
    .about-section {
        max-width: 900px;
        margin: 0 auto;
        line-height: 1.8;
    }
    
    .about-section h2 {
        color: #667eea;
        font-size: 2em;
        margin-bottom: 20px;
        margin-top: 30px;
    }
    
    .about-section h3 {
        color: #764ba2;
        font-size: 1.5em;
        margin-bottom: 15px;
        margin-top: 25px;
    }
    
    .about-section p {
        color: #495057;
        margin-bottom: 15px;
        text-align: justify;
    }
    
    .about-section ul, .about-section ol {
        color: #495057;
        margin-left: 30px;
        margin-bottom: 20px;
    }
    
    .about-section li {
        margin-bottom: 10px;
    }
    
    .highlight-box {
        background: #f8f9fa;
        padding: 25px;
        border-radius: 12px;
        border-left: 5px solid #667eea;
        margin: 25px 0;
    }
    
    .feature-list {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
        gap: 20px;
        margin: 25px 0;
    }
    
    .feature-item {
        background: #f8f9fa;
        padding: 20px;
        border-radius: 8px;
        text-align: center;
    }
    
    .feature-item .icon {
        font-size: 2.5em;
        margin-bottom: 10px;
    }
    
    .feature-item h4 {
        color: #667eea;
        margin-bottom: 10px;
    }
    
    code {
        background: #f8f9fa;
        padding: 2px 8px;
        border-radius: 4px;
        color: #e83e8c;
        font-family: 'Courier New', monospace;
    }
    
    .tech-stack {
        display: flex;
        flex-wrap: wrap;
        gap: 10px;
        margin: 20px 0;
    }
    
    .tech-badge {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 8px 15px;
        border-radius: 20px;
        font-weight: 600;
        font-size: 0.9em;
    }
</style>
{% endblock %}

{% block content %}
<div class="about-section">
    <h2>üö¶ Introduction to Traffic Sign Classification</h2>
    <p>
        The Traffic Sign Classification project is an advanced AI-powered web application that uses 
        deep learning and computer vision techniques to automatically recognize and classify traffic signs. 
        This tool leverages state-of-the-art neural networks to identify 43 different types of traffic signs 
        from the German Traffic Sign Recognition Benchmark (GTSRB) dataset, making it valuable for 
        autonomous vehicle systems, driver assistance applications, and traffic management solutions.
    </p>
    
    <div class="feature-list">
        <div class="feature-item">
            <div class="icon">üéØ</div>
            <h4>High Accuracy</h4>
            <p>Deep learning model with excellent classification performance</p>
        </div>
        <div class="feature-item">
            <div class="icon">‚ö°</div>
            <h4>Fast Processing</h4>
            <p>Real-time classification with confidence scores</p>
        </div>
        <div class="feature-item">
            <div class="icon">üß†</div>
            <h4>Transfer Learning</h4>
            <p>Leverages pre-trained MobileNetV2 architecture</p>
        </div>
        <div class="feature-item">
            <div class="icon">üåê</div>
            <h4>Web Interface</h4>
            <p>Easy-to-use Flask-based web application</p>
        </div>
    </div>
    
    <h2>üìö Importing the Data and Libraries</h2>
    
    <h3>Required Libraries</h3>
    <p>The project uses the following Python libraries:</p>
    
    <div class="tech-stack">
        <span class="tech-badge">TensorFlow 2.13+</span>
        <span class="tech-badge">Flask 2.3.2</span>
        <span class="tech-badge">OpenCV 4.8+</span>
        <span class="tech-badge">NumPy 1.24+</span>
        <span class="tech-badge">Pillow 10.3+</span>
        <span class="tech-badge">scikit-learn 1.3+</span>
    </div>
    
    <div class="highlight-box">
        <h4>Installation Steps:</h4>
        <ol>
            <li><strong>Clone the repository:</strong>
                <br><code>git clone https://github.com/eodenyire/DataScienceProjects.git</code>
                <br><code>cd DataScienceProjects/Project4</code>
            </li>
            <li><strong>Install dependencies:</strong>
                <br><code>pip install -r requirements.txt</code>
            </li>
            <li><strong>Run the application:</strong>
                <br><code>python app.py</code>
            </li>
        </ol>
    </div>
    
    <h2>üñºÔ∏è Image Processing</h2>
    <p>
        The image processing pipeline includes several crucial steps to prepare traffic sign images 
        for classification:
    </p>
    
    <ol>
        <li><strong>Image Loading:</strong> Accept PNG, JPG, and JPEG formats</li>
        <li><strong>Preprocessing:</strong> Resize images to 224√ó224 pixels for model input</li>
        <li><strong>Normalization:</strong> Apply MobileNetV2 preprocessing to normalize pixel values</li>
        <li><strong>Data Augmentation (Training):</strong> Include rotation, shifting, zooming for robust training</li>
        <li><strong>Batch Processing:</strong> Efficiently process images for prediction</li>
    </ol>
    
    <h3>Key Processing Features:</h3>
    <ul>
        <li>Automatic image resizing to match model requirements</li>
        <li>RGB color space conversion for consistency</li>
        <li>Pixel normalization using MobileNetV2 preprocessing</li>
        <li>Support for various image formats and sizes</li>
    </ul>
    
    <h2>ü§ñ Creating and Testing the Model</h2>
    
    <h3>Model Architecture</h3>
    <p>
        The classifier uses transfer learning with MobileNetV2 as the base model. MobileNetV2 is a 
        lightweight deep learning architecture optimized for mobile and embedded vision applications.
    </p>
    
    <div class="highlight-box">
        <h4>Model Components:</h4>
        <ul>
            <li><strong>Base Model:</strong> Pre-trained MobileNetV2 (ImageNet weights)</li>
            <li><strong>Global Average Pooling:</strong> Reduces spatial dimensions</li>
            <li><strong>Dense Layers:</strong> 256 ‚Üí 128 neurons with ReLU activation</li>
            <li><strong>Dropout Layers:</strong> 0.3 and 0.2 dropout rates for regularization</li>
            <li><strong>Output Layer:</strong> 43 neurons with softmax activation (one per class)</li>
        </ul>
    </div>
    
    <h3>Training Process:</h3>
    <ol>
        <li>Load and preprocess training data from directory structure</li>
        <li>Apply data augmentation (rotation, shift, zoom) to improve generalization</li>
        <li>Freeze base model weights to leverage pre-trained features</li>
        <li>Train custom top layers with Adam optimizer</li>
        <li>Use early stopping and learning rate reduction callbacks</li>
        <li>Validate on separate validation set</li>
    </ol>
    
    <h2>üß™ Creating Model for Test Set</h2>
    
    <h3>Prediction Pipeline:</h3>
    <ol>
        <li><strong>Image Upload:</strong> User uploads traffic sign image through web interface</li>
        <li><strong>Preprocessing:</strong> Image is resized and normalized automatically</li>
        <li><strong>Model Inference:</strong> CNN processes the image and outputs probabilities</li>
        <li><strong>Top-3 Predictions:</strong> Display most likely classes with confidence scores</li>
        <li><strong>Result Display:</strong> Show predicted class and visual confidence indicator</li>
    </ol>
    
    <div class="highlight-box">
        <h4>Supported Traffic Sign Classes (43 total):</h4>
        <ul>
            <li>Speed limit signs (20-120 km/h)</li>
            <li>Warning signs (curves, bumps, animals, etc.)</li>
            <li>Mandatory signs (directions, roundabouts)</li>
            <li>Prohibitory signs (no entry, no passing)</li>
            <li>Priority signs (yield, stop, priority road)</li>
        </ul>
    </div>
    
    <h2>üéØ How It Works</h2>
    <ol>
        <li><strong>Upload Phase:</strong> User uploads a traffic sign image</li>
        <li><strong>Preprocessing:</strong> System resizes and normalizes the image</li>
        <li><strong>Feature Extraction:</strong> MobileNetV2 extracts visual features</li>
        <li><strong>Classification:</strong> Dense layers classify the sign type</li>
        <li><strong>Confidence Scoring:</strong> Softmax outputs probability distribution</li>
        <li><strong>Result Display:</strong> Top predictions shown with confidence percentages</li>
    </ol>
    
    <h2>üí° Applications</h2>
    <ul>
        <li><strong>Autonomous Vehicles:</strong> Real-time traffic sign recognition for self-driving cars</li>
        <li><strong>Driver Assistance Systems:</strong> Alert drivers about upcoming signs</li>
        <li><strong>Traffic Management:</strong> Automated sign inventory and monitoring</li>
        <li><strong>Navigation Apps:</strong> Enhanced routing with sign awareness</li>
        <li><strong>Road Safety Research:</strong> Analysis of sign visibility and placement</li>
        <li><strong>Education:</strong> Teaching tool for traffic rules and AI/ML concepts</li>
    </ul>
    
    <h2>üî¨ Technical Details</h2>
    
    <h3>Model Specifications:</h3>
    <ul>
        <li><strong>Input Size:</strong> 224√ó224√ó3 (RGB images)</li>
        <li><strong>Output Classes:</strong> 43 traffic sign categories</li>
        <li><strong>Architecture:</strong> MobileNetV2 + Custom Dense Layers</li>
        <li><strong>Optimizer:</strong> Adam (learning rate: 0.001)</li>
        <li><strong>Loss Function:</strong> Categorical Cross-Entropy</li>
        <li><strong>Evaluation Metric:</strong> Accuracy</li>
    </ul>
    
    <h3>Performance Features:</h3>
    <ul>
        <li>Fast inference time suitable for real-time applications</li>
        <li>Lightweight model architecture (MobileNetV2)</li>
        <li>Confidence scoring for prediction reliability</li>
        <li>Top-3 predictions for alternative classifications</li>
    </ul>
    
    <h2>‚öôÔ∏è Project Structure</h2>
    <div class="highlight-box">
        <code>
            Project4/<br>
            ‚îú‚îÄ‚îÄ app.py                          # Flask web application<br>
            ‚îú‚îÄ‚îÄ traffic_sign_classifier.py      # Classification model<br>
            ‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies<br>
            ‚îú‚îÄ‚îÄ README.md                       # Documentation<br>
            ‚îú‚îÄ‚îÄ templates/                      # HTML templates<br>
            ‚îÇ   ‚îú‚îÄ‚îÄ base.html                  # Base template<br>
            ‚îÇ   ‚îú‚îÄ‚îÄ index.html                 # Home page<br>
            ‚îÇ   ‚îú‚îÄ‚îÄ result.html                # Results page<br>
            ‚îÇ   ‚îî‚îÄ‚îÄ about.html                 # About page<br>
            ‚îú‚îÄ‚îÄ static/uploads/                # Uploaded images<br>
            ‚îî‚îÄ‚îÄ models/                        # Trained model files
        </code>
    </div>
    
    <h2>üöÄ Future Enhancements</h2>
    <ul>
        <li>Support for additional international traffic sign standards</li>
        <li>Real-time video stream processing</li>
        <li>Mobile application development</li>
        <li>Multi-sign detection in single images</li>
        <li>Weather and lighting condition adaptations</li>
        <li>API endpoint for third-party integrations</li>
    </ul>
    
    <h2>üë®‚Äçüíª Developer</h2>
    <p>
        <strong>Emmanuel Odenyire</strong><br>
        This project is part of the Data Science Projects series, demonstrating practical applications 
        of deep learning in computer vision and real-world problem solving.
    </p>
    
    <div style="text-align: center; margin-top: 40px;">
        <a href="{{ url_for('index') }}" class="btn">üîô Back to Home</a>
    </div>
</div>
{% endblock %}
